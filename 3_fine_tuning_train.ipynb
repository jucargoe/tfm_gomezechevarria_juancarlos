{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8510a0-1437-4df5-a334-cf1becc8ce79",
   "metadata": {
    "id": "dc8510a0-1437-4df5-a334-cf1becc8ce79"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# # !pip install werkzeug>=1.0.1\n",
    "# # !pip install markdown>=2.6.8\n",
    "# # !pip install trl\n",
    "# # !pip install tf-keras\n",
    "# # !pip install wandb\n",
    "# !pip install -U peft\n",
    "# !pip install -U datasets\n",
    "# !pip install -U bitsandbytes\n",
    "# !pip install -U transformers\n",
    "# !pip install -U accelerate\n",
    "\n",
    "# for google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6c1c46-bd53-43a4-be99-7e4a85b0f9ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1726767108306,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "eb6c1c46-bd53-43a4-be99-7e4a85b0f9ff",
    "outputId": "f00fb05c-2dd8-4518-f850-c483ffe51d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jc\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\jc\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "hf_token = ''\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c89a1b-1b2f-471e-bf81-71a98e3d1c35",
   "metadata": {
    "executionInfo": {
     "elapsed": 13417,
     "status": "ok",
     "timestamp": 1726767121721,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "e5c89a1b-1b2f-471e-bf81-71a98e3d1c35",
    "outputId": "dc81ab1a-abad-4bac-fd29-184307992258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jc\\.conda\\envs\\tfm_fine_tuning\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161a9df8-4bec-4deb-be10-021b637f2bb9",
   "metadata": {
    "id": "161a9df8-4bec-4deb-be10-021b637f2bb9"
   },
   "outputs": [],
   "source": [
    "# check if torch detects GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    raise Exception('GPU not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "GweKrl6kqfC-",
   "metadata": {
    "id": "GweKrl6kqfC-"
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# OUTPUT_DIR = \"/content/drive/MyDrive/TFM/fine-tuning\"\n",
    "OUTPUT_DIR = \"./fine-tuning\"\n",
    "\n",
    "BASE_MODEL = \"meta-llama/Meta-Llama-3-8B\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4t38WrcYId43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "09da5199390a4079915baa233aa79f4d",
      "0dae19d1b7834166ac5c4071f048b4cb",
      "7b75194bb37c4be9bae59fa595ede223",
      "84dccd9123b64e89b06b57b926457bc1",
      "007faa50cbc94eb2b838749d432d1940",
      "9e63f4a6e13c47b5aebb4b4fa301e9ef",
      "68a8fe7a564040cd9a804630e2684092",
      "c0243034f60e48458ad7f65f09fc82ae",
      "5975278a9f9f42f8bc048f019ee58ebd",
      "22f3ebdbf39547a898d1b71002885141",
      "e3543eedc47d4263aad24aae557ca84a"
     ]
    },
    "executionInfo": {
     "elapsed": 89691,
     "status": "ok",
     "timestamp": 1726767214626,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "4t38WrcYId43",
    "outputId": "c4e3615b-79c9-477f-b4e6-af0e25911f41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 21.18s/it]\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebb003f-48cc-4594-8309-495e4364770b",
   "metadata": {
    "id": "eebb003f-48cc-4594-8309-495e4364770b"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\", split=\"train\")\n",
    "train_dataset = dataset.train_test_split(test_size=0.2)[\"train\"]\n",
    "eval_dataset = dataset.train_test_split(test_size=0.2)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07sw18tQWaPb",
   "metadata": {
    "id": "07sw18tQWaPb"
   },
   "outputs": [],
   "source": [
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "    # \"self-supervised learning\" means the labels are also the inputs:\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "myI1fmo4Wbv6",
   "metadata": {
    "id": "myI1fmo4Wbv6"
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    instruction = data_point[\"instruction\"]\n",
    "    output = data_point[\"output\"]\n",
    "\n",
    "    full_prompt =f\"\"\"\n",
    "You are a powerful text-to-Python model.\n",
    "Your job is to answer questions about a Python.\n",
    "You are given a question regarding Python code.\n",
    "You must output the Python code that answers the question tabulated correctly.\n",
    "Only one response was allowed.\n",
    "### Input:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{output}\n",
    "\"\"\"\n",
    "    return tokenize(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a-umFRsZWdby",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1726767581451,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "a-umFRsZWdby",
    "outputId": "17a6dd3a-0486-42a8-9672-865c63aa093b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14889/14889 [00:06<00:00, 2462.44 examples/s]\n",
      "Map: 100%|██████████| 3723/3723 [00:01<00:00, 2446.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vk6q14VFWjdD",
   "metadata": {
    "id": "vk6q14VFWjdD"
   },
   "outputs": [],
   "source": [
    "model.train() # put model back into training mode\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "WSoK0BQmXCqy",
   "metadata": {
    "id": "WSoK0BQmXCqy"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "zVsOcSR4XFwK",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1726767581451,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "zVsOcSR4XFwK",
    "outputId": "e2c86578-11dd-4b39-af2f-9420ecdffc4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "C:\\Users\\jc\\AppData\\Roaming\\Python\\Python311\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "per_device_train_batch_size = 8 # increase when GPU RAM is higher\n",
    "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=100,\n",
    "        max_steps=400,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        eval_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_steps=20,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        load_best_model_at_end=False,\n",
    "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WOQUJD7lXPSD",
   "metadata": {
    "id": "WOQUJD7lXPSD"
   },
   "outputs": [],
   "source": [
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    print(\"compiling the model\")\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uRFXd7Z9Xo-S",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1726767581452,
     "user": {
      "displayName": "Juan Carlos Gómez Echevarría",
      "userId": "10113025764845079545"
     },
     "user_tz": -120
    },
    "id": "uRFXd7Z9Xo-S",
    "outputId": "fec2fabd-c076-45b3-8634-39a0f68c55ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jc\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\jc\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\jc\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462a287-69cd-454c-8d9a-d470008da709",
   "metadata": {
    "id": "c462a287-69cd-454c-8d9a-d470008da709"
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(f\"{OUTPUT_DIR}/fine_tuned_llama\")\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/fine_tuned_llama\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007faa50cbc94eb2b838749d432d1940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09da5199390a4079915baa233aa79f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dae19d1b7834166ac5c4071f048b4cb",
       "IPY_MODEL_7b75194bb37c4be9bae59fa595ede223",
       "IPY_MODEL_84dccd9123b64e89b06b57b926457bc1"
      ],
      "layout": "IPY_MODEL_007faa50cbc94eb2b838749d432d1940"
     }
    },
    "0dae19d1b7834166ac5c4071f048b4cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e63f4a6e13c47b5aebb4b4fa301e9ef",
      "placeholder": "​",
      "style": "IPY_MODEL_68a8fe7a564040cd9a804630e2684092",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "22f3ebdbf39547a898d1b71002885141": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5975278a9f9f42f8bc048f019ee58ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68a8fe7a564040cd9a804630e2684092": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b75194bb37c4be9bae59fa595ede223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0243034f60e48458ad7f65f09fc82ae",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5975278a9f9f42f8bc048f019ee58ebd",
      "value": 4
     }
    },
    "84dccd9123b64e89b06b57b926457bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22f3ebdbf39547a898d1b71002885141",
      "placeholder": "​",
      "style": "IPY_MODEL_e3543eedc47d4263aad24aae557ca84a",
      "value": " 4/4 [01:26&lt;00:00, 18.80s/it]"
     }
    },
    "9e63f4a6e13c47b5aebb4b4fa301e9ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0243034f60e48458ad7f65f09fc82ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3543eedc47d4263aad24aae557ca84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
